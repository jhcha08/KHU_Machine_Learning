{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20201110.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1nk9igqtVlKE0mE1BBzO4dfpzrkkQD-bF","authorship_tag":"ABX9TyNSbcMwdDMulDDv2A9cIzXs"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vgD9aWohhPJy"},"source":["Lecture 06."]},{"cell_type":"code","metadata":{"id":"e6zLvUorn2-Q"},"source":["from torch import tensor\n","from torch import nn\n","from torch import sigmoid\n","import torch.optim as optim\n","\n","x_data = tensor([[1.0],[2.0],[3.0],[4.0]])\n","y_data = tensor([[0.],[0.],[1.0],[1.0]])\n","\n","class Model(nn.Module):\n","  # 생성자와 forward를 오버라이딩한다 (= 추가한다)\n","  def __init__(self):\n","    super(Model, self).__init__()\n","    self.linear = nn.Linear(1,1) # 1개의 노드로 입력을 받아 1개의 출력을 낸다, 레이어는 하나\n","\n","  def forward(self, x): # 실제 모델이 동작하는 부분\n","    y_pred = sigmoid(self.linear(x))\n","    return y_pred\n","\n","model = Model()\n","\n","criterion = nn.BCELoss(reduction='mean') # 1/n을 곱해준다는 것. 설정 안하면 그냥 sum만 함\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","for epoch in range(1000):\n","  y_pred = model(x_data)\n","\n","  loss = criterion(y_pred, y_data)\n","  print(f'Epoch {epoch+1}/1000 | Loss: {loss.item(): .4f}')\n","\n","  optimizer.zero_grad() # gradient 0으로 초기화\n","  loss.backward() # 각 파라미터에 대한 gradient를 구함\n","  optimizer.step() # 가중치 업데이트\n","\n","# After training\n","print(f'\\nLet\\'s predict the hours need to score above 50%\\n{\"=\" * 50}')\n","hour_var = model(tensor([[1.0]]))\n","print(f'Prediction after 1 hour of training: {hour_var.item():.4f} | Above 50%: {hour_var.item() > 0.5}')\n","hour_var = model(tensor([[7.0]]))\n","print(f'Prediction after 7 hours of training: {hour_var.item():.4f} | Above 50%: { hour_var.item() > 0.5}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Up-2uksahT6K"},"source":["Lecture 07."]},{"cell_type":"code","metadata":{"id":"85Js_FNlrsHU"},"source":["from torch import nn, optim, from_numpy\n","import numpy as np\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","xy = np.loadtxt('/content/drive/My Drive/머신러닝 수업 실습/diabetes.csv.gz', delimiter=',',dtype=np.float32)\n","x_data = from_numpy(xy[:, 0:-1])\n","y_data = from_numpy(xy[:, [-1]])\n","print(f\"XW's shape: {x_data.shape} | YW's shape: {y_data.shape}\")\n","\n","class Model(nn.Module):\n","  def __init__(self):\n","    super(Model, self).__init__()\n","    self.l1 = nn.Linear(8,6)\n","    self.l2 = nn.Linear(6,4) # 이전 output 노드와 앞의 input 노드의 수가 같아야 함\n","    self.l3 = nn.Linear(4,1)\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    out1 = self.sigmoid(self.l1(x))\n","    out2 = self.sigmoid(self.l2(out1))\n","    y_pred = self.sigmoid(self.l3(out2))\n","    return y_pred\n","\n","model = Model()\n","\n","criterion = nn.BCELoss(size_average = True)\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","for epoch in range(1000):\n","  y_pred = model(x_data)\n","  loss = criterion(y_pred, y_data)\n","  print(f'Epoch: {epoch+1}/1000 | Loss: {loss.item(): .4f}')\n","\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()"],"execution_count":null,"outputs":[]}]}