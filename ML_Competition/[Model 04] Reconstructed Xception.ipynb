{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 16, 16]             432\n",
      "       BatchNorm2d-2           [-1, 16, 16, 16]              32\n",
      "              ReLU-3           [-1, 16, 16, 16]               0\n",
      "            Conv2d-4           [-1, 32, 16, 16]           4,608\n",
      "       BatchNorm2d-5           [-1, 32, 16, 16]              64\n",
      "              ReLU-6           [-1, 32, 16, 16]               0\n",
      "            Conv2d-7           [-1, 32, 16, 16]             288\n",
      "            Conv2d-8           [-1, 64, 16, 16]           2,048\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "          Sepconv-10           [-1, 64, 16, 16]               0\n",
      "             ReLU-11           [-1, 64, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]             576\n",
      "           Conv2d-13           [-1, 64, 16, 16]           4,096\n",
      "      BatchNorm2d-14           [-1, 64, 16, 16]             128\n",
      "          Sepconv-15           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-16             [-1, 64, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]           2,048\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]             576\n",
      "           Conv2d-21            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-22            [-1, 128, 8, 8]             256\n",
      "          Sepconv-23            [-1, 128, 8, 8]               0\n",
      "             ReLU-24            [-1, 128, 8, 8]               0\n",
      "           Conv2d-25            [-1, 128, 8, 8]           1,152\n",
      "           Conv2d-26            [-1, 128, 8, 8]          16,384\n",
      "      BatchNorm2d-27            [-1, 128, 8, 8]             256\n",
      "          Sepconv-28            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-29            [-1, 128, 4, 4]               0\n",
      "           Conv2d-30            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-31            [-1, 128, 4, 4]             256\n",
      "             ReLU-32            [-1, 128, 4, 4]               0\n",
      "           Conv2d-33            [-1, 128, 4, 4]           1,152\n",
      "           Conv2d-34            [-1, 270, 4, 4]          34,560\n",
      "      BatchNorm2d-35            [-1, 270, 4, 4]             540\n",
      "          Sepconv-36            [-1, 270, 4, 4]               0\n",
      "             ReLU-37            [-1, 270, 4, 4]               0\n",
      "           Conv2d-38            [-1, 270, 4, 4]           2,430\n",
      "           Conv2d-39            [-1, 270, 4, 4]          72,900\n",
      "      BatchNorm2d-40            [-1, 270, 4, 4]             540\n",
      "          Sepconv-41            [-1, 270, 4, 4]               0\n",
      "        MaxPool2d-42            [-1, 270, 2, 2]               0\n",
      "           Conv2d-43            [-1, 270, 2, 2]          34,560\n",
      "      BatchNorm2d-44            [-1, 270, 2, 2]             540\n",
      "       Entry_flow-45            [-1, 270, 2, 2]               0\n",
      "             ReLU-46            [-1, 270, 2, 2]               0\n",
      "           Conv2d-47            [-1, 270, 2, 2]           2,430\n",
      "           Conv2d-48            [-1, 270, 2, 2]          72,900\n",
      "      BatchNorm2d-49            [-1, 270, 2, 2]             540\n",
      "          Sepconv-50            [-1, 270, 2, 2]               0\n",
      "             ReLU-51            [-1, 270, 2, 2]               0\n",
      "           Conv2d-52            [-1, 270, 2, 2]           2,430\n",
      "           Conv2d-53            [-1, 270, 2, 2]          72,900\n",
      "      BatchNorm2d-54            [-1, 270, 2, 2]             540\n",
      "          Sepconv-55            [-1, 270, 2, 2]               0\n",
      "             ReLU-56            [-1, 270, 2, 2]               0\n",
      "           Conv2d-57            [-1, 270, 2, 2]           2,430\n",
      "           Conv2d-58            [-1, 270, 2, 2]          72,900\n",
      "      BatchNorm2d-59            [-1, 270, 2, 2]             540\n",
      "          Sepconv-60            [-1, 270, 2, 2]               0\n",
      "      Middle_flow-61            [-1, 270, 2, 2]               0\n",
      "             ReLU-62            [-1, 270, 2, 2]               0\n",
      "           Conv2d-63            [-1, 270, 2, 2]           2,430\n",
      "           Conv2d-64            [-1, 270, 2, 2]          72,900\n",
      "      BatchNorm2d-65            [-1, 270, 2, 2]             540\n",
      "          Sepconv-66            [-1, 270, 2, 2]               0\n",
      "             ReLU-67            [-1, 270, 2, 2]               0\n",
      "           Conv2d-68            [-1, 270, 2, 2]           2,430\n",
      "           Conv2d-69            [-1, 512, 2, 2]         138,240\n",
      "      BatchNorm2d-70            [-1, 512, 2, 2]           1,024\n",
      "          Sepconv-71            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-72            [-1, 512, 1, 1]               0\n",
      "           Conv2d-73            [-1, 512, 1, 1]         138,240\n",
      "      BatchNorm2d-74            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-75            [-1, 512, 1, 1]           4,608\n",
      "           Conv2d-76            [-1, 768, 1, 1]         393,216\n",
      "      BatchNorm2d-77            [-1, 768, 1, 1]           1,536\n",
      "          Sepconv-78            [-1, 768, 1, 1]               0\n",
      "             ReLU-79            [-1, 768, 1, 1]               0\n",
      "           Conv2d-80            [-1, 768, 1, 1]           6,912\n",
      "           Conv2d-81           [-1, 1024, 1, 1]         786,432\n",
      "      BatchNorm2d-82           [-1, 1024, 1, 1]           2,048\n",
      "          Sepconv-83           [-1, 1024, 1, 1]               0\n",
      "             ReLU-84           [-1, 1024, 1, 1]               0\n",
      "AdaptiveAvgPool2d-85           [-1, 1024, 1, 1]               0\n",
      "             View-86                 [-1, 1024]               0\n",
      "           Linear-87                   [-1, 10]          10,250\n",
      "        Exit_flow-88                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 1,986,502\n",
      "Trainable params: 1,986,502\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.70\n",
      "Params size (MB): 7.58\n",
      "Estimated Total Size (MB): 10.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class View(nn.Module):\n",
    "\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape) \n",
    "\n",
    "class Sepconv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, outchannel):\n",
    "        super(Sepconv, self).__init__()\n",
    "        sepconv = []\n",
    "        sepconv += [nn.Conv2d(in_channels=in_channel, out_channels=in_channel, kernel_size=3, stride=1, padding=1, groups=in_channel, bias=False),\n",
    "                    nn.Conv2d(in_channels=in_channel, out_channels=outchannel, kernel_size=1, stride=1, bias=False),\n",
    "                    nn.BatchNorm2d(num_features=outchannel)]\n",
    "\n",
    "        self.layers = nn.Sequential(*sepconv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Entry_flow(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Entry_flow, self).__init__()\n",
    "\n",
    "        layer1 = []\n",
    "        layer1 += [nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                   nn.BatchNorm2d(16),\n",
    "                   nn.ReLU(inplace=True),\n",
    "                   nn.Conv2d(16, 32, kernel_size=3, padding=1, bias=False),\n",
    "                   nn.BatchNorm2d(32),\n",
    "                   nn.ReLU(True)]\n",
    "        layer2 = []\n",
    "        layer2 += [Sepconv(32, 64),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(64, 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
    "        layer3 = []\n",
    "        layer3 += [nn.ReLU(True),\n",
    "                   Sepconv(64, 128),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(128, 128),\n",
    "                   nn.MaxPool2d(3, 2, padding=1)]\n",
    "        layer4 = []\n",
    "        layer4 += [nn.ReLU(True),\n",
    "                   Sepconv(128, 270),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(270, 270),\n",
    "                   nn.MaxPool2d(3, 2, padding=1)]\n",
    "\n",
    "        self.layer1 = nn.Sequential(*layer1)\n",
    "        self.layer2 = nn.Sequential(*layer2)\n",
    "        self.layer3 = nn.Sequential(*layer3)\n",
    "        self.layer4 = nn.Sequential(*layer4)\n",
    "        self.skip_con1 = nn.Sequential(*[nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                                         nn.BatchNorm2d(64)])\n",
    "        self.skip_con2 = nn.Sequential(*[nn.Conv2d(64, 128, 1, 2, bias=False),\n",
    "                                         nn.BatchNorm2d(128)])\n",
    "        self.skip_con3 = nn.Sequential(*[nn.Conv2d(128, 270, 1, 2, bias=False),\n",
    "                                         nn.BatchNorm2d(270)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        skip = self.skip_con1(x1)\n",
    "        x2 = x2+skip\n",
    "        x3 = self.layer3(x2)\n",
    "        skip = self.skip_con2(x2)\n",
    "        x3 = x3+skip\n",
    "        x4 = self.layer4(x3)\n",
    "        skip = self.skip_con3(x3)\n",
    "        return x4+skip\n",
    "\n",
    "class Middle_flow(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Middle_flow, self).__init__()\n",
    "\n",
    "        layer = []\n",
    "        layer += [nn.ReLU(True),\n",
    "                  Sepconv(270, 270),\n",
    "                  nn.ReLU(True),\n",
    "                  Sepconv(270, 270),\n",
    "                  nn.ReLU(True),\n",
    "                  Sepconv(270, 270)]\n",
    "\n",
    "        self.layers = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out+x\n",
    "\n",
    "class Exit_flow(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Exit_flow, self).__init__()\n",
    "\n",
    "        layer1 = []\n",
    "        layer1 += [nn.ReLU(True),\n",
    "                   Sepconv(270, 270),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(270, 512),\n",
    "                   nn.MaxPool2d(3, 2, padding=1)]\n",
    "\n",
    "        layer2 = []\n",
    "        layer2 += [Sepconv(512, 768),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(768, 1024),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   View(-1),\n",
    "                   nn.Linear(1024, 10)]\n",
    "\n",
    "        self.layer1 = nn.Sequential(*layer1)\n",
    "        self.layer2 = nn.Sequential(*layer2)\n",
    "        self.skip_con = nn.Conv2d(in_channels=270, out_channels=512, kernel_size=1, stride=2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        skip = self.skip_con(x)\n",
    "        skip = self.bn(skip)\n",
    "        output = self.layer2(out1+skip)\n",
    "        return output\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers += [Entry_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Exit_flow()]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.layers(x)\n",
    "        return y_pred\n",
    "\n",
    "model = Model()\n",
    "from torchsummary import summary\n",
    "summary(model, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
