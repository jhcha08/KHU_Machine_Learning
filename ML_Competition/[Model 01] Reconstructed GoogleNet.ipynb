{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8            [-1, 192, 8, 8]         110,592\n",
      "       BatchNorm2d-9            [-1, 192, 8, 8]             384\n",
      "             ReLU-10            [-1, 192, 8, 8]               0\n",
      "           Conv2d-11             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-12             [-1, 64, 8, 8]             128\n",
      "             ReLU-13             [-1, 64, 8, 8]               0\n",
      "           Conv2d-14             [-1, 96, 8, 8]          18,432\n",
      "      BatchNorm2d-15             [-1, 96, 8, 8]             192\n",
      "             ReLU-16             [-1, 96, 8, 8]               0\n",
      "           Conv2d-17            [-1, 128, 8, 8]         110,592\n",
      "      BatchNorm2d-18            [-1, 128, 8, 8]             256\n",
      "             ReLU-19            [-1, 128, 8, 8]               0\n",
      "           Conv2d-20             [-1, 16, 8, 8]           3,072\n",
      "      BatchNorm2d-21             [-1, 16, 8, 8]              32\n",
      "             ReLU-22             [-1, 16, 8, 8]               0\n",
      "           Conv2d-23             [-1, 32, 8, 8]          12,800\n",
      "      BatchNorm2d-24             [-1, 32, 8, 8]              64\n",
      "             ReLU-25             [-1, 32, 8, 8]               0\n",
      "        MaxPool2d-26            [-1, 192, 8, 8]               0\n",
      "           Conv2d-27             [-1, 32, 8, 8]           6,144\n",
      "      BatchNorm2d-28             [-1, 32, 8, 8]              64\n",
      "             ReLU-29             [-1, 32, 8, 8]               0\n",
      "        Inception-30            [-1, 256, 8, 8]               0\n",
      "           Conv2d-31            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
      "             ReLU-33            [-1, 128, 8, 8]               0\n",
      "           Conv2d-34            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-35            [-1, 128, 8, 8]             256\n",
      "             ReLU-36            [-1, 128, 8, 8]               0\n",
      "           Conv2d-37            [-1, 192, 8, 8]         221,184\n",
      "      BatchNorm2d-38            [-1, 192, 8, 8]             384\n",
      "             ReLU-39            [-1, 192, 8, 8]               0\n",
      "           Conv2d-40             [-1, 32, 8, 8]           8,192\n",
      "      BatchNorm2d-41             [-1, 32, 8, 8]              64\n",
      "             ReLU-42             [-1, 32, 8, 8]               0\n",
      "           Conv2d-43             [-1, 96, 8, 8]          76,800\n",
      "      BatchNorm2d-44             [-1, 96, 8, 8]             192\n",
      "             ReLU-45             [-1, 96, 8, 8]               0\n",
      "        MaxPool2d-46            [-1, 256, 8, 8]               0\n",
      "           Conv2d-47             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-48             [-1, 64, 8, 8]             128\n",
      "             ReLU-49             [-1, 64, 8, 8]               0\n",
      "        Inception-50            [-1, 480, 8, 8]               0\n",
      "        MaxPool2d-51            [-1, 480, 4, 4]               0\n",
      "           Conv2d-52            [-1, 192, 4, 4]          92,160\n",
      "      BatchNorm2d-53            [-1, 192, 4, 4]             384\n",
      "             ReLU-54            [-1, 192, 4, 4]               0\n",
      "           Conv2d-55             [-1, 96, 4, 4]          46,080\n",
      "      BatchNorm2d-56             [-1, 96, 4, 4]             192\n",
      "             ReLU-57             [-1, 96, 4, 4]               0\n",
      "           Conv2d-58            [-1, 208, 4, 4]         179,712\n",
      "      BatchNorm2d-59            [-1, 208, 4, 4]             416\n",
      "             ReLU-60            [-1, 208, 4, 4]               0\n",
      "           Conv2d-61             [-1, 16, 4, 4]           7,680\n",
      "      BatchNorm2d-62             [-1, 16, 4, 4]              32\n",
      "             ReLU-63             [-1, 16, 4, 4]               0\n",
      "           Conv2d-64             [-1, 48, 4, 4]          19,200\n",
      "      BatchNorm2d-65             [-1, 48, 4, 4]              96\n",
      "             ReLU-66             [-1, 48, 4, 4]               0\n",
      "        MaxPool2d-67            [-1, 480, 4, 4]               0\n",
      "           Conv2d-68             [-1, 64, 4, 4]          30,720\n",
      "      BatchNorm2d-69             [-1, 64, 4, 4]             128\n",
      "             ReLU-70             [-1, 64, 4, 4]               0\n",
      "        Inception-71            [-1, 512, 4, 4]               0\n",
      "           Conv2d-72            [-1, 160, 4, 4]          81,920\n",
      "      BatchNorm2d-73            [-1, 160, 4, 4]             320\n",
      "             ReLU-74            [-1, 160, 4, 4]               0\n",
      "           Conv2d-75            [-1, 112, 4, 4]          57,344\n",
      "      BatchNorm2d-76            [-1, 112, 4, 4]             224\n",
      "             ReLU-77            [-1, 112, 4, 4]               0\n",
      "           Conv2d-78            [-1, 224, 4, 4]         225,792\n",
      "      BatchNorm2d-79            [-1, 224, 4, 4]             448\n",
      "             ReLU-80            [-1, 224, 4, 4]               0\n",
      "           Conv2d-81             [-1, 24, 4, 4]          12,288\n",
      "      BatchNorm2d-82             [-1, 24, 4, 4]              48\n",
      "             ReLU-83             [-1, 24, 4, 4]               0\n",
      "           Conv2d-84             [-1, 64, 4, 4]          38,400\n",
      "      BatchNorm2d-85             [-1, 64, 4, 4]             128\n",
      "             ReLU-86             [-1, 64, 4, 4]               0\n",
      "        MaxPool2d-87            [-1, 512, 4, 4]               0\n",
      "           Conv2d-88             [-1, 64, 4, 4]          32,768\n",
      "      BatchNorm2d-89             [-1, 64, 4, 4]             128\n",
      "             ReLU-90             [-1, 64, 4, 4]               0\n",
      "        Inception-91            [-1, 512, 4, 4]               0\n",
      "           Conv2d-92            [-1, 256, 6, 6]         131,072\n",
      "      BatchNorm2d-93            [-1, 256, 6, 6]             512\n",
      "             ReLU-94            [-1, 256, 6, 6]               0\n",
      "           Linear-95                   [-1, 32]         294,944\n",
      "           Linear-96                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 1,923,962\n",
      "Trainable params: 1,923,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.82\n",
      "Params size (MB): 7.34\n",
      "Estimated Total Size (MB): 11.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "        \n",
    "class Inception(nn.Module): # padding은 공식 이용해서 계산, stride는 주어짐, 'S'는 'same', 'V'는 'valid'로 간주\n",
    "    \n",
    "    def __init__(self, common_in_ch, o_c1, o_c2a, i_c2, o_c2b, o_c3a, i_c3, o_c3b, o_c4): \n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        branch1 = []\n",
    "        branch1 += [nn.Conv2d(in_channels = common_in_ch, out_channels = o_c1, kernel_size = 1, stride = 1, padding = 0, bias=False),\n",
    "                    nn.BatchNorm2d(o_c1),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        branch2 = []\n",
    "        branch2 += [nn.Conv2d(in_channels = common_in_ch, out_channels = o_c2a, kernel_size = 1, stride = 1, padding = 0, bias=False),\n",
    "                    nn.BatchNorm2d(o_c2a),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Conv2d(in_channels = i_c2, out_channels = o_c2b, kernel_size = 3, stride = 1, padding = 1, bias=False),\n",
    "                    nn.BatchNorm2d(o_c2b),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        branch3 = []\n",
    "        branch3 += [nn.Conv2d(in_channels = common_in_ch, out_channels = o_c3a, kernel_size = 1, stride = 1, padding = 0, bias=False),\n",
    "                    nn.BatchNorm2d(o_c3a),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Conv2d(in_channels = i_c3, out_channels = o_c3b, kernel_size = 5, stride = 1, padding = 2, bias=False),\n",
    "                    nn.BatchNorm2d(o_c3b),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        branch4 = []\n",
    "        branch4 += [nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
    "                    nn.Conv2d(in_channels = common_in_ch, out_channels = o_c4, kernel_size = 1, padding = 0, bias=False),\n",
    "                    nn.BatchNorm2d(o_c4),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*branch1)\n",
    "        self.layer2 = nn.Sequential(*branch2)\n",
    "        self.layer3 = nn.Sequential(*branch3)\n",
    "        self.layer4 = nn.Sequential(*branch4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x)\n",
    "        x3 = self.layer3(x)\n",
    "        x4 = self.layer4(x)\n",
    "        \n",
    "        out = torch.cat((x1, x2, x3, x4), dim = 1) # (batchsize, channel, width, height)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class GoogleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        \n",
    "        layer1 = []\n",
    "        layer1 += [nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 2, padding = 1, bias=False),\n",
    "                   nn.BatchNorm2d(64),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
    "                   nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 1, stride = 1, padding = 0, bias=False), # (V)로 표시되서 valid로 간주\n",
    "                   nn.BatchNorm2d(64),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(in_channels = 64, out_channels = 192, kernel_size = 3, stride = 1, padding = 1, bias=False),\n",
    "                   nn.BatchNorm2d(192),\n",
    "                   nn.ReLU(True),\n",
    "                   Inception(192, 64, 96, 96, 128, 16, 16, 32, 32),\n",
    "                   Inception(256, 128, 128, 128, 192, 32, 32, 96, 64),\n",
    "                   nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
    "                   Inception(480, 192, 96, 96, 208, 16, 16, 48, 64),\n",
    "                   Inception(512, 160, 112, 112, 224, 24, 24, 64, 64)]\n",
    "\n",
    "        self.layer1 = nn.Sequential(*layer1)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels = 512, out_channels = 256, kernel_size = 1, stride = 1, padding = 1, bias=False)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features = 9216, out_features = 32)\n",
    "        \n",
    "        self.dense2 = nn.Linear(in_features = 32, out_features = 10)\n",
    "\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((5,5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        #x = self.drop(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def Model():\n",
    "    r\"\"\"Return your custom model\n",
    "    \"\"\"\n",
    "    return GoogleNet()\n",
    "\n",
    "model = Model()\n",
    "from torchsummary import summary\n",
    "summary(model, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
