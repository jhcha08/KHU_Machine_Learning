{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Competition_Code.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNz+nmNSaU5qbMgf5013f8N"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"J_PugJq3W2iI"},"source":["from google.colab import drive\r\n","\r\n","# Accessing My Google Drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qb6ArngiW_Mj"},"source":["!unzip '/content/drive/My Drive/CSE331_ML_Project/dataset.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ko8i612GXGkF"},"source":["# PyramidNet with mish\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import math\r\n","import torch.utils.model_zoo as model_zoo\r\n","import torch.nn.functional as F\r\n","\r\n","def mish(x):\r\n","  return x * torch.tanh(F.softplus(x))\r\n","\r\n","def conv3x3(in_planes, out_planes, stride=1):\r\n","    \"3x3 convolution with padding\"\r\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n","                     padding=1, bias=False)\r\n","\r\n","class BasicBlock(nn.Module):\r\n","    outchannel_ratio = 1\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n","        super(BasicBlock, self).__init__()\r\n","        self.bn1 = nn.BatchNorm2d(inplanes)\r\n","        self.conv1 = conv3x3(inplanes, planes, stride)        \r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.conv2 = conv3x3(planes, planes)\r\n","        self.bn3 = nn.BatchNorm2d(planes)\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","\r\n","        out = self.bn1(x)\r\n","        out = self.conv1(out)        \r\n","        out = mish(self.bn2(out))\r\n","        out = self.conv2(out)\r\n","        out = self.bn3(out)\r\n","       \r\n","        if self.downsample is not None:\r\n","            shortcut = self.downsample(x)\r\n","            featuremap_size = shortcut.size()[2:4]\r\n","        else:\r\n","            shortcut = x\r\n","            featuremap_size = out.size()[2:4]\r\n","\r\n","        batch_size = out.size()[0]\r\n","        residual_channel = out.size()[1]\r\n","        shortcut_channel = shortcut.size()[1]\r\n","\r\n","        if residual_channel != shortcut_channel:\r\n","            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \r\n","            out += torch.cat((shortcut, padding), 1)\r\n","        else:\r\n","            out += shortcut \r\n","\r\n","        return out\r\n","\r\n","class Bottleneck(nn.Module):\r\n","    outchannel_ratio = 4\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n","        super(Bottleneck, self).__init__()\r\n","        self.bn1 = nn.BatchNorm2d(inplanes)\r\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.conv2 = nn.Conv2d(planes, (planes*1), kernel_size=3, stride=stride,\r\n","                               padding=1, bias=False)\r\n","        self.bn3 = nn.BatchNorm2d((planes*1))\r\n","        self.conv3 = nn.Conv2d((planes*1), planes * Bottleneck.outchannel_ratio, kernel_size=1, bias=False)\r\n","        self.bn4 = nn.BatchNorm2d(planes * Bottleneck.outchannel_ratio)\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","\r\n","        out = self.bn1(x)\r\n","        out = self.conv1(out)\r\n","        \r\n","        out = mish(self.bn2(out))\r\n","        out = self.conv2(out)\r\n"," \r\n","        out = mish(self.bn3(out))\r\n","        out = self.conv3(out)\r\n","\r\n","        out = self.bn4(out)\r\n","\r\n","        if self.downsample is not None:\r\n","            shortcut = self.downsample(x)\r\n","            featuremap_size = shortcut.size()[2:4]\r\n","        else:\r\n","            shortcut = x\r\n","            featuremap_size = out.size()[2:4]\r\n","\r\n","        batch_size = out.size()[0]\r\n","        residual_channel = out.size()[1]\r\n","        shortcut_channel = shortcut.size()[1]\r\n","\r\n","        if residual_channel != shortcut_channel:\r\n","            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \r\n","            out += torch.cat((shortcut, padding), 1)\r\n","        else:\r\n","            out += shortcut \r\n","\r\n","        return out\r\n","\r\n","class PyramidNet(nn.Module):\r\n","        \r\n","    def __init__(self, dataset, depth, alpha, num_classes, bottleneck=False):\r\n","        super(PyramidNet, self).__init__()   \t\r\n","        self.dataset = dataset\r\n","        if self.dataset.startswith('cifar'):\r\n","            self.inplanes = 16\r\n","            if bottleneck == True:\r\n","                n = int((depth - 2) / 9)\r\n","                block = Bottleneck\r\n","            else:\r\n","                n = int((depth - 2) / 6)\r\n","                block = BasicBlock\r\n","\r\n","            self.addrate = alpha / (3*n*1.0)\r\n","\r\n","            self.input_featuremap_dim = self.inplanes\r\n","            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=3, stride=1, padding=1, bias=False)\r\n","            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\r\n","\r\n","            self.featuremap_dim = self.input_featuremap_dim \r\n","            self.layer1 = self.pyramidal_make_layer(block, n)\r\n","            self.layer2 = self.pyramidal_make_layer(block, n, stride=2)\r\n","            self.layer3 = self.pyramidal_make_layer(block, n, stride=2)\r\n","\r\n","            self.final_featuremap_dim = self.input_featuremap_dim\r\n","            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\r\n","            self.avgpool = nn.AvgPool2d(3)\r\n","            self.fc = nn.Linear(256, num_classes)\r\n","\r\n","        elif dataset == 'imagenet':\r\n","            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\r\n","            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\r\n","\r\n","            if layers.get(depth) is None:\r\n","                if bottleneck == True:\r\n","                    blocks[depth] = Bottleneck\r\n","                    temp_cfg = int((depth-2)/12)\r\n","                else:\r\n","                    blocks[depth] = BasicBlock\r\n","                    temp_cfg = int((depth-2)/8)\r\n","\r\n","                layers[depth]= [temp_cfg, temp_cfg, temp_cfg, temp_cfg]\r\n","                print('=> the layer configuration for each stage is set to', layers[depth])\r\n","\r\n","            self.inplanes = 64            \r\n","            self.addrate = alpha / (sum(layers[depth])*1.0)\r\n","\r\n","            self.input_featuremap_dim = self.inplanes\r\n","            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=7, stride=2, padding=3, bias=False)\r\n","            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\r\n","            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n","\r\n","            self.featuremap_dim = self.input_featuremap_dim \r\n","            self.layer1 = self.pyramidal_make_layer(blocks[depth], layers[depth][0])\r\n","            self.layer2 = self.pyramidal_make_layer(blocks[depth], layers[depth][1], stride=2)\r\n","            self.layer3 = self.pyramidal_make_layer(blocks[depth], layers[depth][2], stride=2)\r\n","            self.layer4 = self.pyramidal_make_layer(blocks[depth], layers[depth][3], stride=2)\r\n","\r\n","            self.final_featuremap_dim = self.input_featuremap_dim\r\n","            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\r\n","            self.avgpool = nn.AvgPool2d(7) \r\n","            self.fc = nn.Linear(256, num_classes)\r\n","\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\r\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                m.weight.data.fill_(1)\r\n","                m.bias.data.zero_()\r\n","\r\n","    def pyramidal_make_layer(self, block, block_depth, stride=1):\r\n","        downsample = None\r\n","        if stride != 1: # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\r\n","            downsample = nn.AvgPool2d((2,2), stride = (2, 2), ceil_mode=True)\r\n","\r\n","        layers = []\r\n","        self.featuremap_dim = self.featuremap_dim + self.addrate\r\n","        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample))\r\n","        for i in range(1, block_depth):\r\n","            temp_featuremap_dim = self.featuremap_dim + self.addrate\r\n","            layers.append(block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1))\r\n","            self.featuremap_dim  = temp_featuremap_dim\r\n","        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\r\n","\r\n","        return nn.Sequential(*layers)\r\n","\r\n","    def forward(self, x):\r\n","        if self.dataset == 'cifar10' or self.dataset == 'cifar100':\r\n","            x = self.conv1(x)\r\n","            x = self.bn1(x)\r\n","            \r\n","            x = self.layer1(x)\r\n","            x = self.layer2(x)\r\n","            x = self.layer3(x)\r\n","\r\n","            x = mish(self.bn_final(x))\r\n","            x = self.avgpool(x)\r\n","            x = x.view(x.size(0), -1)\r\n","            #x = self.fc(x)\r\n","            #x = x.view(x.size(0), -1)\r\n","\r\n","        elif self.dataset == 'imagenet':\r\n","            x = self.conv1(x)\r\n","            x = mish(self.bn1(x))\r\n","            x = self.maxpool(x)\r\n","\r\n","            x = self.layer1(x)\r\n","            x = self.layer2(x)\r\n","            x = self.layer3(x)\r\n","            x = self.layer4(x)\r\n","\r\n","            x = mish(self.bn_final(x))\r\n","            x = self.avgpool(x)\r\n","            x = x.view(x.size(0), -1)\r\n","            x = self.fc(x)\r\n","    \r\n","        return x\r\n","\r\n","def Model():\r\n","    r\"\"\"Return your custom model\r\n","    \"\"\"\r\n","    return PyramidNet('cifar10', 60, 48, 10)\r\n","\r\n","from torchsummary import summary\r\n","model = Model()\r\n","model = model.cuda()\r\n","summary(model, (3,32,32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyq5KTJpX7p4"},"source":["# For Ensemble\r\n","# 앙상블한 모델들은 위에서 정의한 모델과 같음\r\n","\r\n","modelA = Model()\r\n","modelA.load_state_dict(torch.load(SAVEPATH+'model_weight30.pth')) # bs 32, lr 0.001, Adam, 155epoch\r\n","\r\n","modelB = Model()\r\n","modelB.load_state_dict(torch.load(SAVEPATH+'model_weight36.pth')) # bs 32, lr 0.0025, Adam, 155epoch\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","\r\n","class MyEnsemble(nn.Module):\r\n","    def __init__(self, modelA, modelB, nb_classes=10):\r\n","        super(MyEnsemble, self).__init__()\r\n","        self.modelA = modelA\r\n","        self.modelB = modelB\r\n","        self.modelA.fc = nn.Identity()\r\n","        self.modelB.fc = nn.Identity()\r\n","        self.classifier = nn.Linear(256+256, nb_classes)\r\n","        \r\n","    def forward(self, x):\r\n","        x1 = self.modelA(x)\r\n","        x1 = x1.view(x1.size(0), -1)\r\n","        x2 = self.modelB(x)\r\n","        x2 = x2.view(x2.size(0), -1)\r\n","        x = torch.cat((x1, x2), dim=1)\r\n","       # x = self.drop(x)\r\n","        x = self.classifier(swish(x))\r\n","        return x\r\n","\r\n","for param in modelA.parameters():\r\n","    param.requires_grad_(False)\r\n","\r\n","for param in modelB.parameters():\r\n","    param.requires_grad_(False)\r\n","\r\n","def Model():\r\n","    r\"\"\"Return your custom model\r\n","    \"\"\"\r\n","    return MyEnsemble(modelA, modelB)\r\n","\r\n","from torchsummary import summary\r\n","model = Model()\r\n","model = model.cuda()\r\n","summary(model, (3,32,32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VS1s1yisXYoV"},"source":["class AverageMeter(object):\r\n","    r\"\"\"Computes and stores the average and current value\r\n","    \"\"\"\r\n","    def __init__(self, name, fmt=':f'):\r\n","        self.name = name\r\n","        self.fmt = fmt\r\n","        self.reset()\r\n","\r\n","    def reset(self):\r\n","        self.val = 0\r\n","        self.avg = 0\r\n","        self.sum = 0\r\n","        self.count = 0\r\n","\r\n","    def update(self, val, n=1):\r\n","        self.val = val\r\n","        self.sum += val * n\r\n","        self.count += n\r\n","        self.avg = self.sum / self.count\r\n","\r\n","    def __str__(self):\r\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\r\n","        return fmtstr.format(**self.__dict__)\r\n","\r\n","\r\n","class ProgressMeter(object):\r\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\r\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\r\n","        self.meters = meters\r\n","        self.prefix = prefix\r\n","\r\n","    def print(self, batch):\r\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\r\n","        entries += [str(meter) for meter in self.meters]\r\n","        print('\\t'.join(entries))\r\n","\r\n","    def _get_batch_fmtstr(self, num_batches):\r\n","        num_digits = len(str(num_batches // 1))\r\n","        fmt = '{:' + str(num_digits) + 'd}'\r\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\r\n","\r\n","\r\n","def accuracy(output, target, topk=(1,)):\r\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\r\n","    \"\"\"\r\n","    with torch.no_grad():\r\n","        maxk = max(topk)\r\n","        batch_size = target.size(0)\r\n","\r\n","        # _, pred = output.topk(maxk, 1, True, True)\r\n","        # pred = pred.t()\r\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\r\n","\r\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\r\n","        _, idx = output.sort(descending=True)\r\n","        pred = idx[:,:maxk]\r\n","        pred = pred.t()\r\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\r\n","\r\n","        res = []\r\n","\r\n","        for k in topk:\r\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\r\n","            res.append(correct_k.mul_(100.0 / batch_size))\r\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2U-3n6sXaR3"},"source":["SAVEPATH = '/content/drive/My Drive/CSE331_ML_Project/'\r\n","BATCHSIZE = 32\r\n","LR = 0.001\r\n","EPOCHS = 155\r\n","PRINTFREQ = 800"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvDNf_yJXqXH"},"source":["import time\r\n","import warnings\r\n","warnings.filterwarnings(action='ignore')\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import matplotlib.pyplot as plt\r\n","import torchvision\r\n","import torchvision.transforms as transforms\r\n","from torch.utils.data import Dataset, DataLoader\r\n","\r\n","class LabelSmoothLoss(nn.Module):\r\n","    def __init__(self, smoothing=0.0):\r\n","        super(LabelSmoothLoss, self).__init__()\r\n","        self.smoothing = smoothing\r\n","    \r\n","    def forward(self, input, target):\r\n","        log_prob = F.log_softmax(input, dim=-1)\r\n","        weight = input.new_ones(input.size()) * \\\r\n","            self.smoothing / (input.size(-1) - 1.)\r\n","        weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\r\n","        loss = (-weight * log_prob).sum(dim=-1).mean()\r\n","        return loss\r\n","\r\n","def main():\r\n","    model = Model()\r\n","\r\n","    ##### optimizer / learning rate scheduler / criterion #####\r\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\r\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100, 150],\r\n","                                                     gamma=0.1)\r\n","    criterion = LabelSmoothLoss(0.1)\r\n","    ###########################################################\r\n","\r\n","    model = model.cuda()\r\n","    criterion = criterion.cuda()\r\n","\r\n","    # Check number of parameters your model\r\n","    pytorch_total_params = sum(p.numel() for p in model.parameters())\r\n","    print(f\"Number of parameters: {pytorch_total_params}\")\r\n","    if int(pytorch_total_params) > 2000000:\r\n","        print('Your model has the number of parameters more than 2 millions..')\r\n","        return\r\n","\r\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n","                                     std=[0.229, 0.224, 0.225])\r\n","    train_transform = transforms.Compose([\r\n","        transforms.RandomCrop(32, padding=4),\r\n","        transforms.RandomHorizontalFlip(),\r\n","        transforms.ColorJitter(brightness=(0.5,2.5), contrast=(0.5,2.5),\r\n","                              saturation=(0.5,2.5), hue=(-0.1,0.1)),\r\n","        transforms.ToTensor(),\r\n","        transforms.RandomErasing(p=0.5, scale=(0.2,0.2), ratio=(1,1)),\r\n","        transforms.RandomAffine(degrees=10, translate=(0.1,0.1), shear=5),\r\n","        transforms.RandomPerspective(distortion_scale=0.25),\r\n","        normalize\r\n","    ])\r\n","\r\n","    valid_transform = transforms.Compose([\r\n","        transforms.ToTensor(),\r\n","        normalize\r\n","    ])\r\n","\r\n","    train_dataset = torchvision.datasets.ImageFolder(\r\n","        './train', transform=train_transform)\r\n","    train_loader = DataLoader(train_dataset,\r\n","                              batch_size=BATCHSIZE, shuffle=True,\r\n","                              num_workers=4, pin_memory=True)\r\n","    \r\n","    val_dataset = torchvision.datasets.ImageFolder('./valid', transform=valid_transform)\r\n","\r\n","    last_top1_acc = 0\r\n","\r\n","    list_train = []\r\n","    list_loss = []\r\n","\r\n","    for epoch in range(EPOCHS):\r\n","        print(\"\\n----- epoch: {}, lr: {} -----\".format(\r\n","            epoch, optimizer.param_groups[0][\"lr\"]))\r\n","\r\n","        # train for one epoch\r\n","        start_time = time.time()\r\n","        last_top1_acc, train_acc, loss = train(train_loader, epoch, model, optimizer, criterion)\r\n","\r\n","        list_train.append(train_acc)\r\n","        list_loss.append(loss)\r\n","\r\n","        elapsed_time = time.time() - start_time\r\n","        print('==> {:.2f} seconds to train this epoch\\n'.format(\r\n","            elapsed_time))\r\n","\r\n","        # learning rate scheduling\r\n","        scheduler.step()\r\n","\r\n","        # Save model each epoch\r\n","        torch.save(model.state_dict(), SAVEPATH+'model_weight_final.pth')\r\n","\r\n","    print(f\"Last Top-1 Accuracy: {last_top1_acc}\")\r\n","    print(f\"Number of parameters: {pytorch_total_params}\")\r\n","    print('train_acc_list:', list_train)\r\n","    print('loss_list:', list_loss)\r\n","\r\n","    # Write each train accuracy and loss at csv file\r\n","    import csv\r\n","    \r\n","    f_acc = open(SAVEPATH+'train_acc_data_final.csv', 'w', encoding='utf-8')\r\n","    wr_acc = csv.writer(f_acc)\r\n","    wr_acc.writerow(['Epoch', 'Train Acc'])\r\n","\r\n","    for i, train_acc in enumerate(list_train):\r\n","      wr_acc.writerow([i, train_acc])\r\n","    f_acc.close()\r\n","\r\n","    f_loss = open(SAVEPATH+'train_loss_data_final.csv', 'w', encoding='utf-8')\r\n","    wr_loss = csv.writer(f_loss)\r\n","    wr_loss.writerow(['Epoch', 'Train Loss'])\r\n","\r\n","    for i, train_loss in enumerate(list_loss):\r\n","      wr_loss.writerow([i, train_loss])\r\n","    f_loss.close()\r\n","\r\n","    # Plotting Graph for train accuarcy and train loss\r\n","    import matplotlib.pyplot as plt\r\n","\r\n","    list_train = [float(x) for x in list_train]\r\n","    list_loss = [float(x) for x in list_loss]\r\n","\r\n","    epoch_list = range(0, len(list_loss))\r\n","    \r\n","    plt.title('Train Accuracy')\r\n","    plt.plot(epoch_list, list_train)\r\n","    plt.xlabel('epoch')\r\n","    plt.ylabel('Accuracy')\r\n","    plt.legend(['Train'])\r\n","    plt.show()\r\n","\r\n","    plt.title('Train Loss')\r\n","    plt.plot(epoch_list, list_loss)\r\n","    plt.xlabel('epoch')\r\n","    plt.ylabel('Loss')\r\n","    plt.legend(['Loss'])\r\n","    plt.show()\r\n","\r\n","def train(train_loader, epoch, model, optimizer, criterion):\r\n","    batch_time = AverageMeter('Time', ':6.3f')\r\n","    data_time = AverageMeter('Data', ':6.3f')\r\n","    losses = AverageMeter('Loss', ':.4e')\r\n","    top1 = AverageMeter('Acc@1', ':6.2f')\r\n","    top5 = AverageMeter('Acc@5', ':6.2f')\r\n","    progress = ProgressMeter(len(train_loader), batch_time, data_time, losses,\r\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\r\n","    # switch to train mode\r\n","    model.train()\r\n","\r\n","    end = time.time()\r\n","\r\n","    train_acc_list = []\r\n","    loss_list = []\r\n","    \r\n","    for i, (input, target) in enumerate(train_loader):\r\n","        \r\n","        # measure data loading time\r\n","        data_time.update(time.time() - end)\r\n","\r\n","        input = input.cuda()\r\n","        target = target.cuda()\r\n","\r\n","        # compute output\r\n","        output = model(input)\r\n","        loss = criterion(output, target)\r\n","\r\n","        # measure accuracy and record loss, accuracy \r\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\r\n","        losses.update(loss.item(), input.size(0))\r\n","        top1.update(acc1[0].item(), input.size(0))\r\n","        top5.update(acc5[0].item(), input.size(0))\r\n","\r\n","        # compute gradient and do SGD step\r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","\r\n","        # measure elapsed time\r\n","        batch_time.update(time.time() - end)\r\n","        end = time.time()\r\n","\r\n","        if i % PRINTFREQ == 0:\r\n","            progress.print(i)\r\n","\r\n","        if i == round(90000/BATCHSIZE)-1:\r\n","          train_acc_list.append('{top1.avg:.3f}'.format(top1=top1))\r\n","          loss_list.append('{losses.avg:.3f}'.format(losses=losses))\r\n","\r\n","    print('=> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f} Loss {losses.avg:.3f}'\r\n","          .format(top1=top1, top5=top5, losses=losses))\r\n","\r\n","    return top1.avg, train_acc_list[0], loss_list[0]\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()\r\n","\r\n","######################################### Evaluation #########################################\r\n","\r\n","import torch\r\n","import pandas as pd\r\n","import argparse\r\n","import time\r\n","\r\n","\r\n","class TestImageFolder(torchvision.datasets.ImageFolder):\r\n","    def __getitem__(self, index):\r\n","        # return image path\r\n","        return super(TestImageFolder, self).__getitem__(index), self.imgs[index][0].split('/')[-1]\r\n","\r\n","\r\n","def eval():\r\n","    ########## You can change this part only in this cell ##########\r\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n","                                     std=[0.229, 0.224, 0.225])\r\n","    test_transform = transforms.Compose([\r\n","        transforms.ToTensor(),\r\n","        normalize\r\n","    ])\r\n","    ################################################################\r\n","\r\n","    test_dataset = TestImageFolder('./test', transform=test_transform)\r\n","    test_loader = DataLoader(test_dataset, batch_size=BATCHSIZE, num_workers=4, shuffle=False)\r\n","\r\n","    model = Model()\r\n","    model = model.cuda()\r\n","    model.load_state_dict(torch.load(SAVEPATH+'model_weight_final.pth')) \r\n","    model.eval()\r\n","\r\n","    print('Make an evaluation csv file for kaggle submission...')\r\n","    Category = []\r\n","    Id = []\r\n","    for data in test_loader:\r\n","        (input, _), name = data\r\n","        \r\n","        input = input.cuda()\r\n","        output = model(input)\r\n","        output = torch.argmax(output, dim=1)\r\n","        Id = Id + list(name)\r\n","        Category = Category + output.tolist()\r\n","\r\n","    #Id = list(range(0, 90000))\r\n","    samples = {\r\n","       'Id': Id,\r\n","       'Target': Category \r\n","    }\r\n","    df = pd.DataFrame(samples, columns=['Id', 'Target'])\r\n","\r\n","    df.to_csv(SAVEPATH+'submission_final.csv', index=False)\r\n","    print('Done!!')\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","    eval()"],"execution_count":null,"outputs":[]}]}