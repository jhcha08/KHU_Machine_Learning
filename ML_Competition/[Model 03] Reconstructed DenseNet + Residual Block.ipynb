{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 16, 16]             432\n",
      "       BatchNorm2d-2           [-1, 16, 16, 16]              32\n",
      "              ReLU-3           [-1, 16, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 16, 8, 8]               0\n",
      "       BatchNorm2d-5             [-1, 16, 8, 8]              32\n",
      "              ReLU-6             [-1, 16, 8, 8]               0\n",
      "            Conv2d-7             [-1, 16, 8, 8]           2,304\n",
      "       BatchNorm2d-8             [-1, 16, 8, 8]              32\n",
      "              ReLU-9             [-1, 16, 8, 8]               0\n",
      "           Conv2d-10             [-1, 16, 8, 8]           2,304\n",
      "   Residual_Block-11             [-1, 16, 8, 8]               0\n",
      "      BatchNorm2d-12             [-1, 16, 8, 8]              32\n",
      "             ReLU-13             [-1, 16, 8, 8]               0\n",
      "           Conv2d-14             [-1, 64, 8, 8]           1,024\n",
      "      BatchNorm2d-15             [-1, 64, 8, 8]             128\n",
      "             ReLU-16             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-17             [-1, 64, 8, 8]             128\n",
      "             ReLU-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
      "             ReLU-21             [-1, 64, 8, 8]               0\n",
      "           Conv2d-22             [-1, 64, 8, 8]          36,864\n",
      "   Residual_Block-23             [-1, 64, 8, 8]               0\n",
      "           Conv2d-24             [-1, 16, 8, 8]           9,216\n",
      "       Bottleneck-25             [-1, 32, 8, 8]               0\n",
      "      BatchNorm2d-26             [-1, 32, 8, 8]              64\n",
      "             ReLU-27             [-1, 32, 8, 8]               0\n",
      "           Conv2d-28             [-1, 64, 8, 8]           2,048\n",
      "      BatchNorm2d-29             [-1, 64, 8, 8]             128\n",
      "             ReLU-30             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-34             [-1, 64, 8, 8]             128\n",
      "             ReLU-35             [-1, 64, 8, 8]               0\n",
      "           Conv2d-36             [-1, 64, 8, 8]          36,864\n",
      "   Residual_Block-37             [-1, 64, 8, 8]               0\n",
      "           Conv2d-38             [-1, 16, 8, 8]           9,216\n",
      "       Bottleneck-39             [-1, 48, 8, 8]               0\n",
      "      BatchNorm2d-40             [-1, 48, 8, 8]              96\n",
      "             ReLU-41             [-1, 48, 8, 8]               0\n",
      "           Conv2d-42             [-1, 64, 8, 8]           3,072\n",
      "      BatchNorm2d-43             [-1, 64, 8, 8]             128\n",
      "             ReLU-44             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-45             [-1, 64, 8, 8]             128\n",
      "             ReLU-46             [-1, 64, 8, 8]               0\n",
      "           Conv2d-47             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-48             [-1, 64, 8, 8]             128\n",
      "             ReLU-49             [-1, 64, 8, 8]               0\n",
      "           Conv2d-50             [-1, 64, 8, 8]          36,864\n",
      "   Residual_Block-51             [-1, 64, 8, 8]               0\n",
      "           Conv2d-52             [-1, 16, 8, 8]           9,216\n",
      "       Bottleneck-53             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-54             [-1, 64, 8, 8]             128\n",
      "             ReLU-55             [-1, 64, 8, 8]               0\n",
      "           Conv2d-56             [-1, 64, 8, 8]           4,096\n",
      "      BatchNorm2d-57             [-1, 64, 8, 8]             128\n",
      "             ReLU-58             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-59             [-1, 64, 8, 8]             128\n",
      "             ReLU-60             [-1, 64, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      "             ReLU-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64             [-1, 64, 8, 8]          36,864\n",
      "   Residual_Block-65             [-1, 64, 8, 8]               0\n",
      "           Conv2d-66             [-1, 16, 8, 8]           9,216\n",
      "       Bottleneck-67             [-1, 80, 8, 8]               0\n",
      "      BatchNorm2d-68             [-1, 80, 8, 8]             160\n",
      "             ReLU-69             [-1, 80, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]           5,120\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      "             ReLU-72             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-73             [-1, 64, 8, 8]             128\n",
      "             ReLU-74             [-1, 64, 8, 8]               0\n",
      "           Conv2d-75             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-76             [-1, 64, 8, 8]             128\n",
      "             ReLU-77             [-1, 64, 8, 8]               0\n",
      "           Conv2d-78             [-1, 64, 8, 8]          36,864\n",
      "   Residual_Block-79             [-1, 64, 8, 8]               0\n",
      "           Conv2d-80             [-1, 16, 8, 8]           9,216\n",
      "       Bottleneck-81             [-1, 96, 8, 8]               0\n",
      "      BatchNorm2d-82             [-1, 96, 8, 8]             192\n",
      "             ReLU-83             [-1, 96, 8, 8]               0\n",
      "           Conv2d-84             [-1, 64, 8, 8]           6,144\n",
      "      BatchNorm2d-85             [-1, 64, 8, 8]             128\n",
      "             ReLU-86             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-87             [-1, 64, 8, 8]             128\n",
      "             ReLU-88             [-1, 64, 8, 8]               0\n",
      "           Conv2d-89             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-90             [-1, 64, 8, 8]             128\n",
      "             ReLU-91             [-1, 64, 8, 8]               0\n",
      "           Conv2d-92             [-1, 64, 8, 8]          36,864\n",
      "   Residual_Block-93             [-1, 64, 8, 8]               0\n",
      "           Conv2d-94             [-1, 16, 8, 8]           9,216\n",
      "       Bottleneck-95            [-1, 112, 8, 8]               0\n",
      "       DenseBlock-96            [-1, 112, 8, 8]               0\n",
      "      BatchNorm2d-97            [-1, 112, 8, 8]             224\n",
      "             ReLU-98            [-1, 112, 8, 8]               0\n",
      "           Conv2d-99             [-1, 56, 8, 8]          56,448\n",
      "       AvgPool2d-100             [-1, 56, 4, 4]               0\n",
      "Transition_layer-101             [-1, 56, 4, 4]               0\n",
      "     BatchNorm2d-102             [-1, 56, 4, 4]             112\n",
      "            ReLU-103             [-1, 56, 4, 4]               0\n",
      "          Conv2d-104             [-1, 64, 4, 4]           3,584\n",
      "     BatchNorm2d-105             [-1, 64, 4, 4]             128\n",
      "            ReLU-106             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-107             [-1, 64, 4, 4]             128\n",
      "            ReLU-108             [-1, 64, 4, 4]               0\n",
      "          Conv2d-109             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-110             [-1, 64, 4, 4]             128\n",
      "            ReLU-111             [-1, 64, 4, 4]               0\n",
      "          Conv2d-112             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-113             [-1, 64, 4, 4]               0\n",
      "          Conv2d-114             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-115             [-1, 72, 4, 4]               0\n",
      "     BatchNorm2d-116             [-1, 72, 4, 4]             144\n",
      "            ReLU-117             [-1, 72, 4, 4]               0\n",
      "          Conv2d-118             [-1, 64, 4, 4]           4,608\n",
      "     BatchNorm2d-119             [-1, 64, 4, 4]             128\n",
      "            ReLU-120             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-121             [-1, 64, 4, 4]             128\n",
      "            ReLU-122             [-1, 64, 4, 4]               0\n",
      "          Conv2d-123             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-124             [-1, 64, 4, 4]             128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ReLU-125             [-1, 64, 4, 4]               0\n",
      "          Conv2d-126             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-127             [-1, 64, 4, 4]               0\n",
      "          Conv2d-128             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-129             [-1, 88, 4, 4]               0\n",
      "     BatchNorm2d-130             [-1, 88, 4, 4]             176\n",
      "            ReLU-131             [-1, 88, 4, 4]               0\n",
      "          Conv2d-132             [-1, 64, 4, 4]           5,632\n",
      "     BatchNorm2d-133             [-1, 64, 4, 4]             128\n",
      "            ReLU-134             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-135             [-1, 64, 4, 4]             128\n",
      "            ReLU-136             [-1, 64, 4, 4]               0\n",
      "          Conv2d-137             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-138             [-1, 64, 4, 4]             128\n",
      "            ReLU-139             [-1, 64, 4, 4]               0\n",
      "          Conv2d-140             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-141             [-1, 64, 4, 4]               0\n",
      "          Conv2d-142             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-143            [-1, 104, 4, 4]               0\n",
      "     BatchNorm2d-144            [-1, 104, 4, 4]             208\n",
      "            ReLU-145            [-1, 104, 4, 4]               0\n",
      "          Conv2d-146             [-1, 64, 4, 4]           6,656\n",
      "     BatchNorm2d-147             [-1, 64, 4, 4]             128\n",
      "            ReLU-148             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-149             [-1, 64, 4, 4]             128\n",
      "            ReLU-150             [-1, 64, 4, 4]               0\n",
      "          Conv2d-151             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-152             [-1, 64, 4, 4]             128\n",
      "            ReLU-153             [-1, 64, 4, 4]               0\n",
      "          Conv2d-154             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-155             [-1, 64, 4, 4]               0\n",
      "          Conv2d-156             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-157            [-1, 120, 4, 4]               0\n",
      "     BatchNorm2d-158            [-1, 120, 4, 4]             240\n",
      "            ReLU-159            [-1, 120, 4, 4]               0\n",
      "          Conv2d-160             [-1, 64, 4, 4]           7,680\n",
      "     BatchNorm2d-161             [-1, 64, 4, 4]             128\n",
      "            ReLU-162             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-163             [-1, 64, 4, 4]             128\n",
      "            ReLU-164             [-1, 64, 4, 4]               0\n",
      "          Conv2d-165             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-166             [-1, 64, 4, 4]             128\n",
      "            ReLU-167             [-1, 64, 4, 4]               0\n",
      "          Conv2d-168             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-169             [-1, 64, 4, 4]               0\n",
      "          Conv2d-170             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-171            [-1, 136, 4, 4]               0\n",
      "     BatchNorm2d-172            [-1, 136, 4, 4]             272\n",
      "            ReLU-173            [-1, 136, 4, 4]               0\n",
      "          Conv2d-174             [-1, 64, 4, 4]           8,704\n",
      "     BatchNorm2d-175             [-1, 64, 4, 4]             128\n",
      "            ReLU-176             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-177             [-1, 64, 4, 4]             128\n",
      "            ReLU-178             [-1, 64, 4, 4]               0\n",
      "          Conv2d-179             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-180             [-1, 64, 4, 4]             128\n",
      "            ReLU-181             [-1, 64, 4, 4]               0\n",
      "          Conv2d-182             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-183             [-1, 64, 4, 4]               0\n",
      "          Conv2d-184             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-185            [-1, 152, 4, 4]               0\n",
      "     BatchNorm2d-186            [-1, 152, 4, 4]             304\n",
      "            ReLU-187            [-1, 152, 4, 4]               0\n",
      "          Conv2d-188             [-1, 64, 4, 4]           9,728\n",
      "     BatchNorm2d-189             [-1, 64, 4, 4]             128\n",
      "            ReLU-190             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-191             [-1, 64, 4, 4]             128\n",
      "            ReLU-192             [-1, 64, 4, 4]               0\n",
      "          Conv2d-193             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-194             [-1, 64, 4, 4]             128\n",
      "            ReLU-195             [-1, 64, 4, 4]               0\n",
      "          Conv2d-196             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-197             [-1, 64, 4, 4]               0\n",
      "          Conv2d-198             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-199            [-1, 168, 4, 4]               0\n",
      "     BatchNorm2d-200            [-1, 168, 4, 4]             336\n",
      "            ReLU-201            [-1, 168, 4, 4]               0\n",
      "          Conv2d-202             [-1, 64, 4, 4]          10,752\n",
      "     BatchNorm2d-203             [-1, 64, 4, 4]             128\n",
      "            ReLU-204             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-205             [-1, 64, 4, 4]             128\n",
      "            ReLU-206             [-1, 64, 4, 4]               0\n",
      "          Conv2d-207             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-208             [-1, 64, 4, 4]             128\n",
      "            ReLU-209             [-1, 64, 4, 4]               0\n",
      "          Conv2d-210             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-211             [-1, 64, 4, 4]               0\n",
      "          Conv2d-212             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-213            [-1, 184, 4, 4]               0\n",
      "     BatchNorm2d-214            [-1, 184, 4, 4]             368\n",
      "            ReLU-215            [-1, 184, 4, 4]               0\n",
      "          Conv2d-216             [-1, 64, 4, 4]          11,776\n",
      "     BatchNorm2d-217             [-1, 64, 4, 4]             128\n",
      "            ReLU-218             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-219             [-1, 64, 4, 4]             128\n",
      "            ReLU-220             [-1, 64, 4, 4]               0\n",
      "          Conv2d-221             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-222             [-1, 64, 4, 4]             128\n",
      "            ReLU-223             [-1, 64, 4, 4]               0\n",
      "          Conv2d-224             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-225             [-1, 64, 4, 4]               0\n",
      "          Conv2d-226             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-227            [-1, 200, 4, 4]               0\n",
      "     BatchNorm2d-228            [-1, 200, 4, 4]             400\n",
      "            ReLU-229            [-1, 200, 4, 4]               0\n",
      "          Conv2d-230             [-1, 64, 4, 4]          12,800\n",
      "     BatchNorm2d-231             [-1, 64, 4, 4]             128\n",
      "            ReLU-232             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-233             [-1, 64, 4, 4]             128\n",
      "            ReLU-234             [-1, 64, 4, 4]               0\n",
      "          Conv2d-235             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-236             [-1, 64, 4, 4]             128\n",
      "            ReLU-237             [-1, 64, 4, 4]               0\n",
      "          Conv2d-238             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-239             [-1, 64, 4, 4]               0\n",
      "          Conv2d-240             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-241            [-1, 216, 4, 4]               0\n",
      "     BatchNorm2d-242            [-1, 216, 4, 4]             432\n",
      "            ReLU-243            [-1, 216, 4, 4]               0\n",
      "          Conv2d-244             [-1, 64, 4, 4]          13,824\n",
      "     BatchNorm2d-245             [-1, 64, 4, 4]             128\n",
      "            ReLU-246             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-247             [-1, 64, 4, 4]             128\n",
      "            ReLU-248             [-1, 64, 4, 4]               0\n",
      "          Conv2d-249             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-250             [-1, 64, 4, 4]             128\n",
      "            ReLU-251             [-1, 64, 4, 4]               0\n",
      "          Conv2d-252             [-1, 64, 4, 4]          36,864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Residual_Block-253             [-1, 64, 4, 4]               0\n",
      "          Conv2d-254             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-255            [-1, 232, 4, 4]               0\n",
      "     BatchNorm2d-256            [-1, 232, 4, 4]             464\n",
      "            ReLU-257            [-1, 232, 4, 4]               0\n",
      "          Conv2d-258             [-1, 64, 4, 4]          14,848\n",
      "     BatchNorm2d-259             [-1, 64, 4, 4]             128\n",
      "            ReLU-260             [-1, 64, 4, 4]               0\n",
      "     BatchNorm2d-261             [-1, 64, 4, 4]             128\n",
      "            ReLU-262             [-1, 64, 4, 4]               0\n",
      "          Conv2d-263             [-1, 64, 4, 4]          36,864\n",
      "     BatchNorm2d-264             [-1, 64, 4, 4]             128\n",
      "            ReLU-265             [-1, 64, 4, 4]               0\n",
      "          Conv2d-266             [-1, 64, 4, 4]          36,864\n",
      "  Residual_Block-267             [-1, 64, 4, 4]               0\n",
      "          Conv2d-268             [-1, 16, 4, 4]           9,216\n",
      "      Bottleneck-269            [-1, 248, 4, 4]               0\n",
      "      DenseBlock-270            [-1, 248, 4, 4]               0\n",
      "     BatchNorm2d-271            [-1, 248, 4, 4]             496\n",
      "            ReLU-272            [-1, 248, 4, 4]               0\n",
      "          Conv2d-273            [-1, 124, 4, 4]         276,768\n",
      "       AvgPool2d-274            [-1, 124, 2, 2]               0\n",
      "Transition_layer-275            [-1, 124, 2, 2]               0\n",
      "AdaptiveAvgPool2d-276            [-1, 124, 1, 1]               0\n",
      "            View-277                  [-1, 124]               0\n",
      "          Linear-278                   [-1, 10]           1,250\n",
      "================================================================\n",
      "Total params: 1,976,450\n",
      "Trainable params: 1,976,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.55\n",
      "Params size (MB): 7.54\n",
      "Estimated Total Size (MB): 12.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class View(nn.Module):\n",
    "\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "class Residual_Block(nn.Module):  \n",
    "    \n",
    "    def __init__(self, n_ch): \n",
    "        super(Residual_Block, self).__init__() \n",
    "        layers = []\n",
    "        layers += [nn.BatchNorm2d(num_features=n_ch),\n",
    "                  nn.ReLU(inplace=True), \n",
    "                  nn.Conv2d(in_channels=n_ch, out_channels=n_ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                  nn.BatchNorm2d(num_features=n_ch),\n",
    "                  nn.ReLU(inplace=True),\n",
    "                  nn.Conv2d(in_channels=n_ch, out_channels=n_ch, kernel_size=3, stride=1, padding=1, bias=False)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layers(x)\n",
    "        return x + out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.BatchNorm2d(in_ch),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(in_ch, growth_rate*4, kernel_size=1, bias=False),\n",
    "                   nn.BatchNorm2d(growth_rate*4),\n",
    "                   nn.ReLU(True),\n",
    "                   Residual_Block(growth_rate*4),\n",
    "                   nn.Conv2d(growth_rate*4, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = torch.cat((x, out), dim=1)\n",
    "        return out\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers, n_ch, growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            setattr(self, \"Dense_layer_{}\".format(i), Bottleneck(n_ch + i * growth_rate, growth_rate))\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_layers):\n",
    "            x = getattr(self, \"Dense_layer_{}\".format(i))(x)\n",
    "        return x\n",
    "\n",
    "class Transition_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch):\n",
    "        super(Transition_layer, self).__init__()\n",
    "        num_ch = int(in_ch*0.5)\n",
    "        layers = []\n",
    "        layers += [nn.BatchNorm2d(in_ch),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(in_ch, num_ch, kernel_size=3, padding=1, bias=False),\n",
    "                   nn.AvgPool2d(kernel_size=2, stride=2)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                   nn.BatchNorm2d(16),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                   Residual_Block(16),\n",
    "                   DenseBlock(6, 16, 16),\n",
    "                   Transition_layer(112),\n",
    "                   DenseBlock(12, 56, 16),\n",
    "                   Transition_layer(248),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   View(-1),\n",
    "                   #nn.Dropout(0.4),\n",
    "                   nn.Linear(124, 10)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "from torchsummary import summary\n",
    "summary(model, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
