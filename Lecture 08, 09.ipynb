{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20201112.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"15T4EM0m7W7U_HFXP0V9yIsIjmmzxNvZF","authorship_tag":"ABX9TyNOKuLcJ5rIBAFT2GG6xENm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IWiBvlDD6xSD"},"source":["Lecture 08."]},{"cell_type":"code","metadata":{"id":"PvOjzj8I6tes"},"source":["from torch.utils.data import Dataset, DataLoader\n","from torch import from_numpy, tensor\n","import numpy as np\n","\n","# Custom DataLoader\n","\n","class DiabetesDataset(Dataset):\n","\n","  def __init__(self):\n","    xy = np.loadtxt('/content/drive/My Drive/머신러닝 수업 실습/diabetes.csv.gz', delimiter=',',dtype=np.float32)\n","    self.len = xy.shape[0]\n","    self.x_data = from_numpy(xy[:, 0:-1])\n","    self.y_data = from_numpy(xy[:, [-1]])\n","\n","  # 인덱스를 넣었을 때 인덱스에 해당하는 데이터를 반환\n","  def __getitem__(self, index):\n","    return self.x_data[index], self.y_data[index]\n","\n","  # 데이터의 갯수를 반환\n","  def __len__(self):\n","    return self.len\n","\n","dataset = DiabetesDataset()\n","\n","# train_loader: 미니 배치를 관리, 총 320개의 데이터가 있다면 batch size가 32일때 10개씩 끊고, 각 배치에 인덱스를 부여함\n","# num_workers: input되는 이미지의 압축된 bit string을 복호화(decoding)해주는 cpu의 갯수를 정해주는 것 \n","train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)\n","\n","# Testing DataLoader\n","\n","for epoch in range(2):\n","  for i, data in enumerate(train_loader, 0): # enumerate에서 시작하는 index가 0이라는 뜻\n","    # get the inputs\n","    inputs, labels = data\n","\n","    # wrap them in Variable\n","    inputs, labels = tensor(inputs), tensor(labels)\n","\n","    # Run your training process\n","    print(f'Epoch: {i} | Inputs {inputs.data} | Labels {labels.data}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIUxAyf16wGh"},"source":["import torch\n","from torch import nn, optim\n","\n","# Classifying Diabetes\n","\n","class Model(nn.Module): # 모듈을 상속받아 모델을 만듦\n","\n","  def __init__(self):\n","    super(Model, self).__init__()\n","    self.l1 = nn.Linear(8,6)\n","    self.l2 = nn.Linear(6,4)\n","    self.l3 = nn.Linear(4,1)\n","\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    out1 = self.sigmoid(self.l1(x))\n","    out2 = self.sigmoid(self.l2(out1))\n","    y_pred = self.sigmoid(self.l3(out2))\n","\n","    return y_pred\n","\n","model = Model()\n","\n","criterion = nn.BCELoss(reduction='sum')\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# Training loop\n","for epoch in range(100):\n","  for i, data in enumerate(train_loader, 0): \n","    # get the inputs\n","    inputs, labels = data\n","\n","    # Forward pass: Compute predicted y by passing x to the model\n","    y_pred = model(inputs)\n","\n","    # Compute and print loss\n","    loss = criterion(y_pred, labels)\n","    print(f'Epoch {epoch+1} | Batch: {i+1} | Loss: {loss.item(): .4f}')\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NvDjbuOOsOaI"},"source":["Exercise 8-1 (Build DataLoader for Titanic dataset, Build a classifier using the DataLoader)"]},{"cell_type":"code","metadata":{"id":"pZ9X2nbMQsXE"},"source":["import numpy as np\n","import torch\n","from torch import from_numpy, nn, optim\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","# 필요한 정보만 추려내고, 문자열은 int형으로 변환하는 전처리 함수\n","\n","def preprocess():\n","  data = pd.read_csv('/content/drive/My Drive/머신러닝 수업 실습/titanic.csv', delimiter=',')\n","  data = data.dropna() # nan값 삭제\n","  data = data.drop(['Name', 'PassengerId', 'Ticket', 'Cabin'], 1) # 필요없다고 생각되는 열들 삭제\n","  data = data.replace({'Sex':'female'},{'Sex':1}) # string형 값들 int 형으로 변환\n","  data = data.replace({'Sex':'male'},{'Sex':0})\n","  data = data.replace({'Embarked':'S'},{'Embarked':2})\n","  data = data.replace({'Embarked':'C'},{'Embarked':1})\n","  data = data.replace({'Embarked':'Q'},{'Embarked':0})\n","  data.to_csv('/content/drive/My Drive/머신러닝 수업 실습/titanic_preprocess.csv', index=False, header=False)\n","\n","# Custom DataLoader\n","\n","class TitanicDataset(Dataset):\n","\n","  def __init__(self):\n","    preprocess()\n","    xy = np.loadtxt('/content/drive/My Drive/머신러닝 수업 실습/titanic_preprocess.csv', delimiter=',',dtype=np.float32)\n","    self.len = xy.shape[0]\n","    self.x_data = from_numpy(xy[:, 1:])\n","    self.y_data = from_numpy(xy[:, [0]]) # 생존 여부 (0 or 1)\n","\n","  def __getitem__(self, index):\n","    return self.x_data[index], self.y_data[index]\n","\n","  def __len__(self):\n","    return self.len\n","\n","dataset = TitanicDataset()\n","train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)\n","\n","class Model(nn.Module):\n","\n","  def __init__(self):\n","    super(Model, self).__init__()\n","    self.l1 = nn.Linear(7,5)\n","    self.l2 = nn.Linear(5,4)\n","    self.l3 = nn.Linear(4,1)\n","\n","  def forward(self, x):\n","    out1 = F.relu(self.l1(x))\n","    out2 = F.relu(self.l2(out1))\n","    y_pred = F.sigmoid(self.l3(out2))\n","\n","    return y_pred\n","\n","model = Model()\n","\n","criterion = nn.BCELoss(reduction='sum')\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","for epoch in range(100):\n","  for i, data in enumerate(train_loader, 0): \n","    inputs, labels = data\n","    y_pred = model(inputs)\n","    loss = criterion(y_pred, labels)\n","    print(f'Epoch {epoch+1} | Batch: {i+1} | Loss: {loss.item(): .4f}')\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0cCIM-VW64tT"},"source":["Lecture 09."]},{"cell_type":"code","metadata":{"id":"d8v93o3267UK"},"source":["from __future__ import print_function\n","from torch import nn, optim, cuda\n","from torch.utils import data\n","from torchvision import datasets, transforms\n","import torch.nn.functional as F\n","import time\n","\n","# Training settings\n","batch_size = 64\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n","\n","# MNIST Dataset\n","train_dataset = datasets.MNIST(root='./mnist_data/',\n","                               train=True,\n","                               transform=transforms.ToTensor(),\n","                               download=True)\n","\n","test_dataset = datasets.MNIST(root='./mnist_data/',\n","                              train=False,\n","                              transform=transforms.TOTensor())\n","\n","# Data Loader (Input Pipeline)\n","train_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shffle=True)\n","test_loader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shffle=False)\n","\n","# LeNet-5\n","class Net(nn.Module):\n","\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.l1 = nn.Linear(784, 520)\n","    self.l2 = nn.Linear(520, 320)\n","    self.l3 = nn.Linear(320, 240)\n","    self.l4 = nn.Linear(240, 120)\n","    self.l5 = nn.Linear(120, 10)\n","\n","  def forward(self, x):\n","    x = x.view(-1, 784) # Flatten the data (n, 1, 28, 28) -> (n, 784)\n","    x = F.relu(self.l1(x))\n","    x = F.relu(self.l2(x))\n","    x = F.relu(self.l3(x))\n","    x = F.relu(self.l4(x))\n","    x = F.relu(self.l5(x))\n","    return x\n","\n","model = Net()\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n","\n","def train(epoch):\n","  model.train()\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","    data, target = data.to(device), target.to(device) # ?\n","    optimizer.zero_grad() # V\n","    output = model(data)\n","    loss = criterion(output, target) \n","    loss.backward() # V\n","    optimizer.step() # V : V 체크한 곳은 train의 맨 마지막에 있어도 되나?\n","    if batch_idx % 10 == 0:\n","      print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","      \n","def test():\n","  model.eval()\n","  test_loss = 0\n","  correct = 0\n","  for data, target in test_loader:\n","    data, target = data.to(device), target.to(device)\n","    output = model(data)\n","    # sum up batch loss\n","    test_loss += criterion(output, target.item()) # ?\n","    # get the index of the max\n","    pred = output.data.max(1, keepdim=True)[1] # ?\n","    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","\n","  test_loss /= len(test_loader.dataset)\n","  print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n","          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n","  \n","if __name__ == '__main__':\n","    since = time.time()\n","    for epoch in range(1,10):\n","      epoch_start = time.time()\n","      train(epoch)\n","      m, s = divmod(time.time() - epoch_start, 60)\n","      print(f'Training time: {m:.0f}m {s:.0f}s')\n","      test()\n","      m, s = divmod(time.time() - epoch_start, 60)\n","      print(f'Testing time: {m:.0f}m {s:.0f}s')\n","\n","    m, s = divmod(time.time() - since, 60)\n","    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zYo3OApJ-mOd"},"source":["Exercise 9-2 (Build a classifier for Otto Group Product, Use Data Loader)"]},{"cell_type":"code","metadata":{"id":"jgzFVWnXFI4I"},"source":["import numpy as np\n","import torch\n","from torch import from_numpy, nn, optim\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import warnings \n","warnings.filterwarnings('ignore') \n","\n","# 전처리\n","\n","def preprocess():\n","  df = pd.read_csv('/content/drive/My Drive/머신러닝 수업 실습/otto.csv', delimiter=',')\n","  df = df.drop(['id'],1)\n","  df['target'] = df['target'].map({'Class_1' : 1, 'Class_2' : 2, 'Class_3' : 3, 'Class_4' : 4, 'Class_5' : 5, \n","                                   'Class_6' : 6, 'Class_7' : 7, 'Class_8' : 8, 'Class_9' : 9}).astype(int)\n","  df.to_csv('/content/drive/My Drive/머신러닝 수업 실습/otto_preprocess.csv', index=False, header=False)\n","\n","# Custom DataLoader\n","\n","class OttoDataset(Dataset):\n","\n","  def __init__(self):\n","    preprocess()\n","    xy = np.loadtxt('/content/drive/My Drive/머신러닝 수업 실습/otto_preprocess.csv', delimiter=',',dtype=np.float32)\n","    self.len = xy.shape[0]\n","    self.x_data = from_numpy(xy[:, 0:-1])\n","    self.y_data = from_numpy(xy[:, [-1]])\n","\n","  def __getitem__(self, idx):\n","    return self.x_data[idx], self.y_data[idx]\n","\n","  def __len__(self):\n","    return self.len\n","\n","dataset = OttoDataset()\n","\n","train_loader = DataLoader(dataset=dataset, batch_size=256, shuffle=True, num_workers=2)\n","\n","class Model(nn.Module):\n","\n","  def __init__(self):\n","    super(Model, self).__init__()\n","    self.l1 = nn.Linear(93,75)\n","    self.l2 = nn.Linear(75,65)\n","    self.l3 = nn.Linear(65,55)\n","    self.l4 = nn.Linear(55,33)\n","    self.l5 = nn.Linear(33,22)\n","    self.l6 = nn.Linear(22,9)\n","\n","  def forward(self, x):\n","    out1 = F.relu(self.l1(x))\n","    out2 = F.relu(self.l2(out1))\n","    out3 = F.relu(self.l3(out2))\n","    out4 = F.relu(self.l4(out3))\n","    out5 = F.relu(self.l5(out4))\n","    y_pred = F.relu(self.l6(out5))\n","\n","    return y_pred\n","\n","model = Model()\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","for epoch in range(100):\n","  for i, data in enumerate(train_loader, 0): \n","    inputs, labels = data\n","    y_pred = model(inputs)\n","    loss = criterion(y_pred, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  print(f'Epoch {epoch+1} | Loss: {loss.item(): .4f}')"],"execution_count":null,"outputs":[]}]}